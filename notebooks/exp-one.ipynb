{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the train and test sets\n",
    "# train_df = pd.read_csv('train_data.csv')\n",
    "# test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "# # Combine the two datasets. Set ignore_index to False.\n",
    "# df = pd.concat([train_df,test_df],ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# df.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Waikato Times: Hamilton and Waikato news</td>\n",
       "      <td>https://www.stuff.co.nz/waikato-times</td>\n",
       "      <td>stuff.co.nz</td>\n",
       "      <td>2012-09-16 04:44:50</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Southland Times: Southland /Invercargill news</td>\n",
       "      <td>https://www.stuff.co.nz/southland-times</td>\n",
       "      <td>stuff.co.nz</td>\n",
       "      <td>2012-09-16 04:44:57</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports: Rugby, cricket, football, All Blacks</td>\n",
       "      <td>https://www.stuff.co.nz/sport</td>\n",
       "      <td>stuff.co.nz</td>\n",
       "      <td>2012-09-16 04:46:00</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Real-Time News from PennLive</td>\n",
       "      <td>https://www.pennlive.com/news/</td>\n",
       "      <td>pennlive.com</td>\n",
       "      <td>2015-10-23 16:44:48</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020 Playoffs: Feels like 2010‚Ä¶</td>\n",
       "      <td>https://www.nhl.com/canadiens/news/</td>\n",
       "      <td>nhl.com</td>\n",
       "      <td>2016-09-23 08:46:28</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0       Waikato Times: Hamilton and Waikato news   \n",
       "1  Southland Times: Southland /Invercargill news   \n",
       "2   Sports: Rugby, cricket, football, All Blacks   \n",
       "3                   Real-Time News from PennLive   \n",
       "4                2020 Playoffs: Feels like 2010‚Ä¶   \n",
       "\n",
       "                                      link        domain       published_date  \\\n",
       "0    https://www.stuff.co.nz/waikato-times   stuff.co.nz  2012-09-16 04:44:50   \n",
       "1  https://www.stuff.co.nz/southland-times   stuff.co.nz  2012-09-16 04:44:57   \n",
       "2            https://www.stuff.co.nz/sport   stuff.co.nz  2012-09-16 04:46:00   \n",
       "3           https://www.pennlive.com/news/  pennlive.com  2015-10-23 16:44:48   \n",
       "4      https://www.nhl.com/canadiens/news/       nhl.com  2016-09-23 08:46:28   \n",
       "\n",
       "           topic  \n",
       "0  ENTERTAINMENT  \n",
       "1         SPORTS  \n",
       "2         SPORTS  \n",
       "3        SCIENCE  \n",
       "4         SPORTS  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"backup.csv\")\n",
    "# df =df.sample(10000,random_state=42)\n",
    "# df.to_csv('sample.csv',index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"link\",\"domain\",\"published_date\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "BUSINESS         13.8%\n",
       "ENTERTAINMENT    13.8%\n",
       "HEALTH           13.8%\n",
       "NATION           13.8%\n",
       "SCIENCE           3.5%\n",
       "SPORTS           13.8%\n",
       "TECHNOLOGY       13.8%\n",
       "WORLD            13.8%\n",
       "Name: proportion, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The percentage of each class in the data\n",
    "\n",
    "df.topic.value_counts(normalize=True).sort_index().mul(100).round(1).astype(str) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('ÿõ', \"\")\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['title'] = df['title'].apply(lower_case)\n",
    "        df['title'] = df['title'].apply(remove_stop_words)\n",
    "        df['title'] = df['title'].apply(removing_numbers)\n",
    "        df['title'] = df['title'].apply(removing_punctuations)\n",
    "        df['title'] = df['title'].apply(removing_urls)\n",
    "        df['title'] = df['title'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waikato time hamilton waikato news</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southland time southland invercargill news</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport rugby cricket football black</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>real time news pennlive</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>playoff feel like ‚Ä¶</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title          topic\n",
       "0          waikato time hamilton waikato news  ENTERTAINMENT\n",
       "1  southland time southland invercargill news         SPORTS\n",
       "2          sport rugby cricket football black         SPORTS\n",
       "3                     real time news pennlive        SCIENCE\n",
       "4                         playoff feel like ‚Ä¶         SPORTS"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"topic\"] = label_encoder.fit_transform(df[\"topic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=20000)\n",
    "X = vectorizer.fit_transform(df['title'])\n",
    "y = df['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f410016b94419f81eb7509b40f6e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=0220acbd-dd69-4c26-b2bf-5f7115d09138&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=5c8677e544562eeae0083c2259f4e78360c44e15ce463689c49992895013c498\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as bhauryal7\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as bhauryal7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"bhauryal7/NewsClassification\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"bhauryal7/NewsClassification\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository bhauryal7/NewsClassification initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository bhauryal7/NewsClassification initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/49127cd8129d4f7da5c8e6ddcf808605', creation_time=1742312611100, experiment_id='0', last_update_time=1742312611100, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/bhauryal7/NewsClassification.mlflow')\n",
    "dagshub.init(repo_owner='bhauryal7', repo_name='NewsClassification', mlflow=True)\n",
    "\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 16:11:10,990 - INFO - Starting MLflow run...\n",
      "2025-04-03 16:11:11,221 - INFO - Logging preprocessing parameters...\n",
      "2025-04-03 16:11:11,932 - INFO - Initializing Logistic Regression model...\n",
      "2025-04-03 16:11:11,933 - INFO - Fitting the model...\n",
      "2025-04-03 16:11:17,079 - INFO - Model training complete.\n",
      "2025-04-03 16:11:17,079 - INFO - Logging model parameters...\n",
      "2025-04-03 16:11:17,296 - INFO - Making predictions...\n",
      "2025-04-03 16:11:17,309 - INFO - Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      2931\n",
      "           1       0.84      0.89      0.86      3093\n",
      "           2       0.77      0.83      0.80      3029\n",
      "           3       0.65      0.70      0.68      2984\n",
      "           4       0.89      0.76      0.82       713\n",
      "           5       0.92      0.92      0.92      2932\n",
      "           6       0.90      0.86      0.88      3021\n",
      "           7       0.72      0.63      0.67      3052\n",
      "\n",
      "    accuracy                           0.80     21755\n",
      "   macro avg       0.81      0.80      0.80     21755\n",
      "weighted avg       0.80      0.80      0.80     21755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 16:11:18,346 - INFO - Saving and logging the model...\n",
      "\u001b[31m2025/04/03 16:11:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-04-03 16:11:27,668 - INFO - Model training and logging completed in 16.45 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bald-boar-700 at: https://dagshub.com/bhauryal7/NewsClassification.mlflow/#/experiments/0/runs/1db01c1c34dd4ef5aed16ec7207927dd\n",
      "üß™ View experiment at: https://dagshub.com/bhauryal7/NewsClassification.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"TfidfVectorizer\")\n",
    "        mlflow.log_param(\"num_features\", 20000)\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "\n",
    "        logging.info(\"Initializing Logistic Regression model...\")\n",
    "        model = LogisticRegression(C=1,max_iter=1000)  # Increase max_iter to prevent non-convergence issues\n",
    "\n",
    "        logging.info(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        logging.info(\"Model training complete.\")\n",
    "\n",
    "        logging.info(\"Logging model parameters...\")\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        class_report = classification_report(y_test,y_pred)\n",
    "\n",
    "        print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "        # Log metrics in MLflow\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_text(class_report, \"classification_report.txt\")\n",
    "\n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # Log execution time\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
